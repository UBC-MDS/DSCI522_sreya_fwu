{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_data-analysis.ipynb\n",
    "\n",
    "# PURPOSE: The script takes the clean crime dataset and fit the dataset into decision tree model\n",
    "#\n",
    "# ARGUMENTS:\n",
    "#     ARG1 = input file path\n",
    "#     ARG2 = output file path\n",
    "#\n",
    "# USAGE: \"python src/data_analysis.py data/crime_1617_clean_data.csv results/\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def main():\n",
    "    input_file = sys.argv[1]\n",
    "    output_file = sys.argv[2]\n",
    "    data_analysis(input_file, output_file)\n",
    "    \n",
    "\n",
    "def mapping_ref(df, col):\n",
    "    '''create reference mapping table'''\n",
    "    temp_df = df[[col]]\n",
    "    count_df = pd.DataFrame(temp_df.groupby(col).size().sort_values(ascending=False).rename('Count').reset_index())\n",
    "    ref_df = count_df[col].values.tolist()\n",
    "    return ref_df\n",
    "\n",
    "def split_train_test(X,y,num):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=num, random_state = 48)\n",
    "    return Xtrain, Xtest, ytrain, ytest\n",
    "\n",
    "\n",
    "def cross_validation(n, model, Xtest, ytest):\n",
    "    cv_scores = cross_val_score(model, Xtest, ytest, cv=n)\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_df = pd.DataFrame({\"index\" : list(range(1,n+1)),\n",
    "                          \"cv_score\": cv_scores})\n",
    "    return cv_df\n",
    "\n",
    "\n",
    "def decision_tree_model(df, feature_cols):\n",
    "    #get X and y\n",
    "    X = df.loc[:,feature_cols]\n",
    "    y = df.Arrest\n",
    "    Xtrain, Xtest, ytrain, ytest = split_train_test(X,y,0.3)\n",
    "    \n",
    "    #fit a decision tree model using sklearn\n",
    "    model = tree.DecisionTreeClassifier(max_depth=5)\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    predictions = model.predict(Xtest)\n",
    "    \n",
    "    #generate prediction summary\n",
    "    pred_dict = Xtest.copy()\n",
    "    pred_dict['Target'] = ytest\n",
    "    pred_dict['Prediction'] = predictions\n",
    "    \n",
    "    #run 10-fold cross validation \n",
    "    cv_df = cross_validation(10, model, Xtest, ytest)\n",
    "    \n",
    "    return pred_dict, model, cv_df\n",
    "\n",
    "\n",
    "def feat_importance(model, feature_cols):\n",
    "    feat = model.tree_.compute_feature_importances(normalize=False)\n",
    "    feat_df = pd.DataFrame([feat], columns = feature_cols)\n",
    "    return feat_df\n",
    "\n",
    "def export_csv(output_file, filename, df):\n",
    "    df.to_csv(output_file + filename, index=False)\n",
    "    \n",
    "def data_analysis(input_file, output_file):\n",
    "    #import clean data\n",
    "    crime_df = pd.read_csv(input_file)\n",
    "    \n",
    "    # modify data types\n",
    "    pt_ref = mapping_ref(crime_df, 'Primary.Type')\n",
    "    loc_ref = mapping_ref(crime_df, 'Location.Description')\n",
    "    crime_df['Primary.Type.Num'] = crime_df['Primary.Type'].apply(lambda x: pt_ref.index(x))\n",
    "    crime_df['Location.Description.Num'] = crime_df['Location.Description'].apply(lambda x: loc_ref.index(x))\n",
    "    \n",
    "    #modeling by decision tree\n",
    "    feature_cols = ['Primary.Type.Num','Location.Description.Num','Domestic','Latitude','Longitude']\n",
    "    pred_dict, model, cv_df = decision_tree_model(crime_df, feature_cols)\n",
    "    \n",
    "    #for report purpose, we mapping the primary.type and location description back based on the reference tables\n",
    "    pred_dict.insert(loc=0, column='Primary.Type', value=pred_dict['Primary.Type.Num'].apply(lambda x: pt_ref[x]))\n",
    "    pred_dict.insert(loc=1, column='Location.Description', value=pred_dict['Location.Description.Num'].apply(lambda x: loc_ref[x]))\n",
    "    pred_dict = pred_dict.drop(columns = ['Primary.Type.Num','Location.Description.Num'])\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    #cv_df = cross_validation(10, model, Xtest, ytest)\n",
    "    \n",
    "    #features importance\n",
    "    feat_df = feat_importance(model, feature_cols)\n",
    "    \n",
    "    #save the model to disk\n",
    "    model_file = output_file + \"crime_1617_decisiontree_model.sav\"\n",
    "    pickle.dump(model, open(model_file, 'wb'))\n",
    "    \n",
    "    \n",
    "    #export the results as csv file\n",
    "    export_csv(output_file, \"crime_1617_decisiontree_result.csv\", pred_dict)\n",
    "    export_csv(output_file, \"crime_1617_decisiontree_cvscores.csv\", cv_df)\n",
    "    export_csv(output_file, \"crime_1617_decisiontree_featuresimportance.csv\", feat_df)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
