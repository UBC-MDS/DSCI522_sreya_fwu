{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_data-analysis.ipynb\n",
    "# \n",
    "# TEAM: Fan Wu & Sreya Guha\n",
    "# DATE: November 23, 2018\n",
    "#\n",
    "# PURPOSE: The script takes the clean crime dataset, select five specific columns as features, \n",
    "#          split the dataset as train and test sets (i.e. 7:3), and fit it into a decision tree model.\n",
    "#          The script also performs a 10-fold cross validation and features importance examine for the \n",
    "#          model and provides the corresponding scores.\n",
    "#\n",
    "# INPUT:\n",
    "#      - Clean Dataset: \"data/crime_1617_clean_data.csv\"\n",
    "#\n",
    "# OUTPUTS:\n",
    "#      - Decision Tree Model: \"results/crime_1617_decisiontree_model.sav\"\n",
    "#      - Prediction Results: \"results/crime_1617_decisiontree_result.csv\"\n",
    "#      - Cross Validation Scores: \"results/crime_1617_decisiontree_cvscores.csv\"\n",
    "#      - Features Importance: \"results/crime_1617_decisiontree_featuresimportance.csv\"\n",
    "#\n",
    "# ARGUMENTS:\n",
    "#     ARG1 = input file path\n",
    "#     ARG2 = output file path\n",
    "#\n",
    "# USAGE: \"python src/03_data-analysis.py data/crime_1617_clean_data.csv results/\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def main():\n",
    "    \n",
    "    '''main function: grab the arg1 and arg2 as input file path and output file path '''\n",
    "    \n",
    "    input_file = sys.argv[1]\n",
    "    output_file = sys.argv[2]\n",
    "    data_analysis(input_file, output_file)\n",
    "    \n",
    "\n",
    "def mapping_ref(df, col):\n",
    "    \n",
    "    '''create reference mapping table based on the provided dataframe'''\n",
    "    \n",
    "    temp_df = df[[col]]\n",
    "    count_df = pd.DataFrame(temp_df.groupby(col).size().sort_values(ascending=False).rename('Count').reset_index())\n",
    "    ref_df = count_df[col].values.tolist()\n",
    "    return ref_df\n",
    "\n",
    "def split_train_test(X,y,num):\n",
    "    \n",
    "    '''split the train and test datasets based on the test size provided (i.e. num)'''\n",
    "    \n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=num, random_state = 48)\n",
    "    return Xtrain, Xtest, ytrain, ytest\n",
    "\n",
    "def kfold_cv(Xtrain,ytrain):\n",
    "    \n",
    "    '''k-fold cross_validation function to find out the best depth for the tree'''\n",
    "    \n",
    "    accuracy = []\n",
    "    depth = range(1, 20)\n",
    "    for i in depth:\n",
    "        tree = DecisionTreeClassifier(max_depth = i)\n",
    "        tree.fit(Xtrain, ytrain)\n",
    "        accuracy.append(np.mean(cross_val_score(tree, Xtrain, ytrain, cv = 5)))\n",
    "    result_depth = depths[np.argmax(test_acc)]\n",
    "    return result_depth\n",
    "\n",
    "def cross_validation(n, model, Xtest, ytest):\n",
    "    \n",
    "    '''cross_validation function to examine the model accurcy based on the test set provided'''\n",
    "    \n",
    "    cv_scores = cross_val_score(model, Xtest, ytest, cv=n)\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_df = pd.DataFrame({\"index\" : list(range(1,n+1)),\n",
    "                          \"cv_score\": cv_scores})\n",
    "    return cv_df\n",
    "\n",
    "\n",
    "def decision_tree_model(df, feature_cols):\n",
    "    \n",
    "    '''decision_tree_model function takes a dataframe and an array for features, fits a decision\n",
    "       tree model with max_depth as 5, and provides prediction results for the test set'''\n",
    "    \n",
    "    #get X and y\n",
    "    X = df.loc[:,feature_cols]\n",
    "    y = df.Arrest\n",
    "    Xtrain, Xtest, ytrain, ytest = split_train_test(X,y,0.3)\n",
    "    \n",
    "    #fit a decision tree model using sklearn\n",
    "    model = tree.DecisionTreeClassifier(max_depth=kfold_cv(Xtrain,ytrain))\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    predictions = model.predict(Xtest)\n",
    "    \n",
    "    #generate prediction summary\n",
    "    pred_dict = Xtest.copy()\n",
    "    pred_dict['Target'] = ytest\n",
    "    pred_dict['Prediction'] = predictions\n",
    "    \n",
    "    #run 10-fold cross validation \n",
    "    cv_df = cross_validation(10, model, Xtest, ytest)\n",
    "    \n",
    "    return pred_dict, model, cv_df\n",
    "\n",
    "\n",
    "def feat_importance(model, feature_cols):\n",
    "    \n",
    "    '''The feat_importance function takes a model and an array of features, and performs a \n",
    "       feature importance examine'''\n",
    "    \n",
    "    feat = model.tree_.compute_feature_importances(normalize=False)\n",
    "    feat_df = pd.DataFrame([feat], columns = feature_cols)\n",
    "    return feat_df\n",
    "\n",
    "def export_csv(output_file, filename, df):\n",
    "    \n",
    "    '''export_csv function generate csv file at a specific output file path'''\n",
    "    \n",
    "    df.to_csv(output_file + filename, index=False)\n",
    "    \n",
    "def data_analysis(input_file, output_file):\n",
    "    \n",
    "    '''data_analysis function provides a general routine for a decision tree modeling'''\n",
    "    \n",
    "    #import clean dataset\n",
    "    crime_df = pd.read_csv(input_file)\n",
    "    \n",
    "    # modify data types for `Primary.Type` and `Location.Description` to numerical values\n",
    "    pt_ref = mapping_ref(crime_df, 'Primary.Type')\n",
    "    loc_ref = mapping_ref(crime_df, 'Location.Description')\n",
    "    crime_df['Primary.Type.Num'] = crime_df['Primary.Type'].apply(lambda x: pt_ref.index(x))\n",
    "    crime_df['Location.Description.Num'] = crime_df['Location.Description'].apply(lambda x: loc_ref.index(x))\n",
    "    \n",
    "    #modeling by decision tree\n",
    "    feature_cols = ['Primary.Type.Num','Location.Description.Num','Domestic','Latitude','Longitude']\n",
    "    pred_dict, model, cv_df = decision_tree_model(crime_df, feature_cols)\n",
    "    \n",
    "    #for report purpose, we map the primary.type and location description back to categorical values based on the reference tables\n",
    "    pred_dict.insert(loc=0, column='Primary.Type', value=pred_dict['Primary.Type.Num'].apply(lambda x: pt_ref[x]))\n",
    "    pred_dict.insert(loc=1, column='Location.Description', value=pred_dict['Location.Description.Num'].apply(lambda x: loc_ref[x]))\n",
    "    pred_dict = pred_dict.drop(columns = ['Primary.Type.Num','Location.Description.Num'])\n",
    "    \n",
    "    #features importance examine\n",
    "    feat_df = feat_importance(model, feature_cols)\n",
    "    \n",
    "    #save the model to disk\n",
    "    model_file = output_file + \"crime_1617_decisiontree_model.sav\"\n",
    "    pickle.dump(model, open(model_file, 'wb'))\n",
    "    \n",
    "    #export the results as csv files\n",
    "    export_csv(output_file, \"crime_1617_decisiontree_result.csv\", pred_dict)\n",
    "    export_csv(output_file, \"crime_1617_decisiontree_cvscores.csv\", cv_df)\n",
    "    export_csv(output_file, \"crime_1617_decisiontree_featuresimportance.csv\", feat_df)\n",
    "\n",
    "#call main function\n",
    "if __name__ == '__main__':\n",
    "    main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
